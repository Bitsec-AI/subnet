"""
Comprehensive vulnerability report generation module.

This module aggregates vulnerability findings from multiple miners, applies consensus
mechanisms to identify true positives, and generates detailed reports for users.
"""

import logging
import json
from typing import Dict, List, Set, Any, Optional, Tuple, Union
from dataclasses import dataclass, field
from datetime import datetime
import os
from pathlib import Path
import numpy as np
from collections import defaultdict
import matplotlib.pyplot as plt
import pandas as pd
from io import BytesIO
import base64

@dataclass
class VulnerabilityLocation:
    """
    Data class representing the location of a vulnerability in code.
    
    Attributes:
        file_path: Path to the file containing the vulnerability
        line_start: Starting line number
        line_end: Ending line number (if applicable)
        function_name: Name of the function containing the vulnerability (if applicable)
        contract_name: Name of the contract containing the vulnerability (if applicable)
    """
    file_path: str
    line_start: int
    line_end: Optional[int] = None
    function_name: Optional[str] = None
    contract_name: Optional[str] = None
    
    def __hash__(self) -> int:
        """Define hash method for use in sets and dictionaries."""
        return hash((self.file_path, self.line_start, self.line_end))
    
    def __eq__(self, other) -> bool:
        """Define equality for use in sets and dictionaries."""
        if not isinstance(other, VulnerabilityLocation):
            return False
        return (self.file_path == other.file_path and 
                self.line_start == other.line_start and
                self.line_end == other.line_end)

@dataclass
class VulnerabilityFinding:
    """
    Data class representing a consolidated vulnerability finding.
    
    Attributes:
        vulnerability_type: Type of vulnerability (e.g., "reentrancy", "overflow")
        location: Location of the vulnerability in the code
        severity: Severity level (1-10)
        confidence: Confidence level (0-1)
        description: Description of the vulnerability
        recommendation: Recommendation for fixing the vulnerability
        miners: List of miner IDs that reported this vulnerability
        code_snippet: Related code snippet
        exploit_scenario: Example exploit scenario
        references: Related references (URLs, papers, etc.)
    """
    vulnerability_type: str
    location: VulnerabilityLocation
    severity: float
    confidence: float
    description: str = ""
    recommendation: str = ""
    miners: List[str] = field(default_factory=list)
    code_snippet: Optional[str] = None
    exploit_scenario: Optional[str] = None
    references: List[str] = field(default_factory=list)
    
    def __hash__(self) -> int:
        """Define hash method for use in sets and dictionaries."""
        return hash((self.vulnerability_type, hash(self.location)))
    
    def __eq__(self, other) -> bool:
        """Define equality for use in sets and dictionaries."""
        if not isinstance(other, VulnerabilityFinding):
            return False
        return (self.vulnerability_type == other.vulnerability_type and 
                self.location == other.location)
    
    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary for serialization."""
        return {
            "vulnerability_type": self.vulnerability_type,
            "location": {
                "file_path": self.location.file_path,
                "line_start": self.location.line_start,
                "line_end": self.location.line_end,
                "function_name": self.location.function_name,
                "contract_name": self.location.contract_name
            },
            "severity": self.severity,
            "confidence": self.confidence,
            "description": self.description,
            "recommendation": self.recommendation,
            "miners": self.miners,
            "code_snippet": self.code_snippet,
            "exploit_scenario": self.exploit_scenario,
            "references": self.references,
            "miner_count": len(self.miners)
        }
    
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'VulnerabilityFinding':
        """Create from dictionary after deserialization."""
        location_data = data.get("location", {})
        location = VulnerabilityLocation(
            file_path=location_data.get("file_path", ""),
            line_start=location_data.get("line_start", 0),
            line_end=location_data.get("line_end"),
            function_name=location_data.get("function_name"),
            contract_name=location_data.get("contract_name")
        )
        
        return cls(
            vulnerability_type=data.get("vulnerability_type", ""),
            location=location,
            severity=data.get("severity", 0.0),
            confidence=data.get("confidence", 0.0),
            description=data.get("description", ""),
            recommendation=data.get("recommendation", ""),
            miners=data.get("miners", []),
            code_snippet=data.get("code_snippet"),
            exploit_scenario=data.get("exploit_scenario"),
            references=data.get("references", [])
        )

@dataclass
class VulnerabilityReport:
    """
    Data class representing a comprehensive vulnerability report.
    
    Attributes:
        report_id: Unique identifier for the report
        timestamp: Time when the report was generated
        project_name: Name of the project being analyzed
        findings: List of vulnerability findings
        statistics: Statistical summary of findings
        overall_security_score: Overall security score (0-100)
        miner_contributions: Dictionary mapping miner IDs to their contribution metrics
    """
    report_id: str
    timestamp: datetime
    project_name: str
    findings: List[VulnerabilityFinding]
    statistics: Dict[str, Any]
    overall_security_score: float
    miner_contributions: Dict[str, Dict[str, Any]]
    
    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary for serialization."""
        return {
            "report_id": self.report_id,
            "timestamp": self.timestamp.isoformat(),
            "project_name": self.project_name,
            "findings": [finding.to_dict() for finding in self.findings],
            "statistics": self.statistics,
            "overall_security_score": self.overall_security_score,
            "miner_contributions": self.miner_contributions
        }
    
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'VulnerabilityReport':
        """Create from dictionary after deserialization."""
        findings = [
            VulnerabilityFinding.from_dict(finding_data)
            for finding_data in data.get("findings", [])
        ]
        
        return cls(
            report_id=data.get("report_id", ""),
            timestamp=datetime.fromisoformat(data.get("timestamp", datetime.now().isoformat())),
            project_name=data.get("project_name", ""),
            findings=findings,
            statistics=data.get("statistics", {}),
            overall_security_score=data.get("overall_security_score", 0.0),
            miner_contributions=data.get("miner_contributions", {})
        )
    
    def save_json(self, output_path: str) -> None:
        """Save report to JSON file."""
        with open(output_path, 'w') as f:
            json.dump(self.to_dict(), f, indent=2)
    
    @classmethod
    def load_json(cls, input_path: str) -> 'VulnerabilityReport':
        """Load report from JSON file."""
        with open(input_path, 'r') as f:
            data = json.load(f)
        return cls.from_dict(data)
    
    def get_critical_findings(self) -> List[VulnerabilityFinding]:
        """Get critical findings (high severity and confidence)."""
        return [f for f in self.findings 
                if f.severity >= 8.0 and f.confidence >= 0.8]
    
    def get_findings_by_type(self, vuln_type: str) -> List[VulnerabilityFinding]:
        """Get findings of a specific vulnerability type."""
        return [f for f in self.findings if f.vulnerability_type == vuln_type]
    
    def get_findings_by_file(self, file_path: str) -> List[VulnerabilityFinding]:
        """Get findings in a specific file."""
        return [f for f in self.findings if f.location.file_path == file_path]


class VulnerabilityReportGenerator:
    """
    Class for generating comprehensive vulnerability reports.
    
    This class processes vulnerability findings from multiple miners,
    applies consensus mechanisms, and generates detailed reports.
    """
    
    def __init__(self, 
                 storage_path: Optional[str] = None,
                 consensus_threshold: float = 0.25,
                 min_miners_for_consensus: int = 2,
                 false_positive_threshold: float = 0.1):
        """
        Initialize the report generator.
        
        Args:
            storage_path: Path to store generated reports
            consensus_threshold: Minimum fraction of miners required for consensus
            min_miners_for_consensus: Minimum number of miners required for consensus
            false_positive_threshold: Threshold below which findings are considered false positives
        """
        # Configuration
        self.consensus_threshold = consensus_threshold
        self.min_miners_for_consensus = min_miners_for_consensus
        self.false_positive_threshold = false_positive_threshold
        
        # Storage setup
        if storage_path:
            self.storage_path = Path(storage_path)
        else:
            self.storage_path = Path(os.path.expanduser("~/.bitsec/reports"))
        
        self.storage_path.mkdir(parents=True, exist_ok=True)
        
        # Set up logging
        self.logger = logging.getLogger("bitsec.vulnerability_report")
    
    def generate_report(self, 
                       project_name: str,
                       miner_responses: Dict[str, Any],
                       miner_weights: Optional[Dict[str, float]] = None) -> VulnerabilityReport:
        """
        Generate a comprehensive vulnerability report from miner responses.
        
        Args:
            project_name: Name of the project being analyzed
            miner_responses: Dictionary mapping miner IDs to their responses
            miner_weights: Optional dictionary mapping miner IDs to their weights
            
        Returns:
            A comprehensive vulnerability report
        """
        # Use equal weights if not provided
        if miner_weights is None:
            miner_weights = {miner_id: 1.0 for miner_id in miner_responses}
        
        # Normalize weights
        total_weight = sum(miner_weights.values())
        if total_weight > 0:
            normalized_weights = {
                miner_id: weight / total_weight 
                for miner_id, weight in miner_weights.items()
            }
        else:
            normalized_weights = {miner_id: 1.0 / len(miner_weights) for miner_id in miner_weights}
        
        # Extract and consolidate findings
        raw_findings = self._extract_raw_findings(miner_responses)
        consolidated_findings = self._consolidate_findings(raw_findings, miner_responses, normalized_weights)
        
        # Generate statistics
        statistics = self._generate_statistics(consolidated_findings, miner_responses)
        
        # Calculate overall security score
        security_score = self._calculate_security_score(consolidated_findings, statistics)
        
        # Calculate miner contributions
        miner_contributions = self._calculate_miner_contributions(
            consolidated_findings, miner_responses, normalized_weights
        )
        
        # Create report ID
        import uuid
        report_id = str(uuid.uuid4())
        
        # Create and save report
        report = VulnerabilityReport(
            report_id=report_id,
            timestamp=datetime.now(),
            project_name=project_name,
            findings=consolidated_findings,
            statistics=statistics,
            overall_security_score=security_score,
            miner_contributions=miner_contributions
        )
        
        # Save report to disk
        self._save_report(report)
        
        return report
    
    def _extract_raw_findings(self, miner_responses: Dict[str, Any]) -> Dict[str, List[Dict[str, Any]]]:
        """
        Extract raw vulnerability findings from miner responses.
        
        Args:
            miner_responses: Dictionary mapping miner IDs to their responses
            
        Returns:
            Dictionary mapping miner IDs to their raw findings
        """
        raw_findings = {}
        
        for miner_id, response in miner_responses.items():
            try:
                # Extract vulnerabilities from the response
                # This assumes a response structure with a 'vulnerabilities' field
                # Adjust based on actual response structure
                if hasattr(response, 'vulnerabilities'):
                    vulnerabilities = response.vulnerabilities
                elif isinstance(response, dict) and 'vulnerabilities' in response:
                    vulnerabilities = response['vulnerabilities']
                else:
                    self.logger.warning(f"Could not extract vulnerabilities from miner {miner_id} response")
                    vulnerabilities = []
                
                raw_findings[miner_id] = vulnerabilities
                
            except Exception as e:
                self.logger.error(f"Error extracting findings from miner {miner_id}: {e}")
                raw_findings[miner_id] = []
        
        return raw_findings
    
    def _consolidate_findings(self, 
                             raw_findings: Dict[str, List[Dict[str, Any]]],
                             miner_responses: Dict[str, Any],
                             miner_weights: Dict[str, float]) -> List[VulnerabilityFinding]:
        """
        Consolidate raw findings into a list of unique vulnerability findings.
        
        Args:
            raw_findings: Dictionary mapping miner IDs to their raw findings
            miner_responses: Original miner responses for additional context
            miner_weights: Dictionary mapping miner IDs to their normalized weights
            
        Returns:
            List of consolidated vulnerability findings
        """
        # Group similar findings
        findings_by_location = defaultdict(list)
        findings_by_type_location = defaultdict(list)
        
        # First pass: group by location and type+location
        for miner_id, findings in raw_findings.items():
            for finding in findings:
                try:
                    # Extract location
                    location = self._extract_location(finding)
                    
                    # Extract vulnerability type
                    vuln_type = self._extract_vulnerability_type(finding)
                    
                    # Add to location group
                    findings_by_location[self._location_key(location)].append((miner_id, finding))
                    
                    # Add to type+location group
                    key = (vuln_type, self._location_key(location))
                    findings_by_type_location[key].append((miner_id, finding))
                    
                except Exception as e:
                    self.logger.error(f"Error processing finding from miner {miner_id}: {e}")
        
        # Apply consensus mechanism
        consolidated_findings = []
        processed_keys = set()
        
        # First, process type+location groups (most specific)
        for key, group in findings_by_type_location.items():
            vuln_type, location_key = key
            
            # Skip if too few miners reported this
            if len(set(miner_id for miner_id, _ in group)) < self.min_miners_for_consensus:
                continue
            
            # Skip if below consensus threshold
            total_miners = len(raw_findings)
            if len(set(miner_id for miner_id, _ in group)) / total_miners < self.consensus_threshold:
                continue
            
            # Create consolidated finding
            finding = self._create_consolidated_finding(vuln_type, location_key, group, miner_weights)
            consolidated_findings.append(finding)
            processed_keys.add(location_key)
        
        # Then, process location groups (less specific, for findings not yet processed)
        for location_key, group in findings_by_location.items():
            # Skip if already processed
            if location_key in processed_keys:
                continue
            
            # Skip if too few miners reported this
            if len(set(miner_id for miner_id, _ in group)) < self.min_miners_for_consensus:
                continue
            
            # Skip if below consensus threshold
            total_miners = len(raw_findings)
            if len(set(miner_id for miner_id, _ in group)) / total_miners < self.consensus_threshold:
                continue
            
            # Determine most common vulnerability type for this location
            type_counts = defaultdict(int)
            for _, finding in group:
                vuln_type = self._extract_vulnerability_type(finding)
                type_counts[vuln_type] += 1
            
            most_common_type = max(type_counts.items(), key=lambda x: x[1])[0]
            
            # Create consolidated finding
            finding = self._create_consolidated_finding(most_common_type, location_key, group, miner_weights)
            consolidated_findings.append(finding)
        
        # Sort findings by severity and confidence
        consolidated_findings.sort(key=lambda x: (x.severity, x.confidence), reverse=True)
        
        return consolidated_findings
    
    def _extract_location(self, finding: Dict[str, Any]) -> VulnerabilityLocation:
        """
        Extract location information from a finding.
        
        Args:
            finding: Raw vulnerability finding
            
        Returns:
            VulnerabilityLocation object
        """
        # Adapt this based on the actual structure of findings
        try:
            file_path = finding.get('file_path', '')
            line_start = finding.get('line_number', 0) or finding.get('line_start', 0)
            line_end = finding.get('line_end')
            function_name = finding.get('function_name')
            contract_name = finding.get('contract_name')
            
            return VulnerabilityLocation(
                file_path=file_path,
                line_start=line_start,
                line_end=line_end,
                function_name=function_name,
                contract_name=contract_name
            )
        except Exception as e:
            self.logger.error(f"Error extracting location: {e}")
            return VulnerabilityLocation(file_path="unknown", line_start=0)
    
    def _extract_vulnerability_type(self, finding: Dict[str, Any]) -> str:
        """
        Extract vulnerability type from a finding.
        
        Args:
            finding: Raw vulnerability finding
            
        Returns:
            Vulnerability type as string
        """
        # Adapt this based on the actual structure of findings
        return finding.get('type', '') or finding.get('vulnerability_type', 'unknown')
    
    def _location_key(self, location: VulnerabilityLocation) -> str:
        """
        Create a key for grouping findings by location.
        
        Args:
            location: VulnerabilityLocation object
            
        Returns:
            String key for the location
        """
        return f"{location.file_path}:{location.line_start}-{location.line_end or location.line_start}"
    
    def _create_consolidated_finding(self, 
                                    vuln_type: str,
                                    location_key: str,
                                    group: List[Tuple[str, Dict[str, Any]]],
                                    miner_weights: Dict[str, float]) -> VulnerabilityFinding:
        """
        Create a consolidated finding from a group of similar findings.
        
        Args:
            vuln_type: Vulnerability type
            location_key: Location key
            group: List of (miner_id, finding) tuples
            miner_weights: Dictionary mapping miner IDs to their weights
            
        Returns:
            Consolidated VulnerabilityFinding object
        """
        # Extract location from the first finding
        location = self._extract_location(group[0][1])
        
        # Collect all miner IDs
        miner_ids = [miner_id for miner_id, _ in group]
        
        # Calculate weighted average severity
        severities = [finding.get('severity', 5.0) for _, finding in group]
        if not severities or all(s is None for s in severities):
            severities = [5.0] * len(group)  # Default severity
        severities = [s if s is not None else 5.0 for s in severities]
        
        weights = [miner_weights.get(miner_id, 0.0) for miner_id, _ in group]
        severity = np.average(severities, weights=weights) if sum(weights) > 0 else np.mean(severities)
        
        # Calculate confidence based on consensus
        unique_miners = len(set(miner_ids))
        total_miners = len(miner_weights)
        base_confidence = unique_miners / total_miners
        
        # Adjust confidence based on miner weights
        weighted_confidence = sum(miner_weights.get(miner_id, 0.0) for miner_id in set(miner_ids))
        confidence = (base_confidence + weighted_confidence) / 2
        
        # Collect descriptions and recommendations
        descriptions = [finding.get('description', '') for _, finding in group]
        descriptions = [d for d in descriptions if d]
        
        recommendations = [finding.get('recommendation', '') for _, finding in group]
        recommendations = [r for r in recommendations if r]
        
        # Get the most detailed description and recommendation
        description = max(descriptions, key=len) if descriptions else ""
        recommendation = max(recommendations, key=len) if recommendations else ""
        
        # Collect code snippets
        code_snippets = [finding.get('code_snippet', '') for _, finding in group]
        code_snippets = [cs for cs in code_snippets if cs]
        code_snippet = max(code_snippets, key=len) if code_snippets else None
        
        # Collect exploit scenarios
        exploit_scenarios = [finding.get('exploit_scenario', '') for _, finding in group]
        exploit_scenarios = [es for es in exploit_scenarios if es]
        exploit_scenario = max(exploit_scenarios, key=len) if exploit_scenarios else None
        
        # Collect references
        references = []
        for _, finding in group:
            refs = finding.get('references', [])
            if isinstance(refs, list):
                references.extend(refs)
            elif isinstance(refs, str):
                references.append(refs)
        references = list(set(references))  # Remove duplicates
        
        return VulnerabilityFinding(
            vulnerability_type=vuln_type,
            location=location,
            severity=severity,
            confidence=confidence,
            description=description,
            recommendation=recommendation,
            miners=miner_ids,
            code_snippet=code_snippet,
            exploit_scenario=exploit_scenario,
            references=references
        )
    
    def _generate_statistics(self, 
                            findings: List[VulnerabilityFinding],
                            miner_responses: Dict[str, Any]) -> Dict[str, Any]:
        """
        Generate statistical summaries of the findings.
        
        Args:
            findings: List of consolidated findings
            miner_responses: Original miner responses
            
        Returns:
            Dictionary of statistics
        """
        # Count findings by severity
        severity_counts = {
            "critical": sum(1 for f in findings if f.severity >= 9.0),
            "high": sum(1 for f in findings if 7.0 <= f.severity < 9.0),
            "medium": sum(1 for f in findings if 4.0 <= f.severity < 7.0),
            "low": sum(1 for f in findings if f.severity < 4.0)
        }
        
        # Count findings by type
        type_counts = defaultdict(int)
        for finding in findings:
            type_counts[finding.vulnerability_type] += 1
        
        # Count findings by file
        file_counts = defaultdict(int)
        for finding in findings:
            file_counts[finding.location.file_path] += 1
        
        # Generate consensus statistics
        consensus_stats = {
            "total_findings": len(findings),
            "avg_miners_per_finding": np.mean([len(f.miners) for f in findings]) if findings else 0,
            "max_miners_per_finding": max([len(f.miners) for f in findings]) if findings else 0,
            "min_miners_per_finding": min([len(f.miners) for f in findings]) if findings else 0,
        }
        
        # Top vulnerable files
        top_files = sorted(file_counts.items(), key=lambda x: x[1], reverse=True)[:5]
        
        # Top vulnerability types
        top_types = sorted(type_counts.items(), key=lambda x: x[1], reverse=True)[:5]
        
        return {
            "severity_counts": severity_counts,
            "type_counts": dict(type_counts),
            "file_counts": dict(file_counts),
            "consensus_stats": consensus_stats,
            "top_vulnerable_files": dict(top_files),
            "top_vulnerability_types": dict(top_types)
        }
    
    def _calculate_security_score(self, 
                                 findings: List[VulnerabilityFinding],
                                 statistics: Dict[str, Any]) -> float:
        """
        Calculate an overall security score based on findings.
        
        Args:
            findings: List of consolidated findings
            statistics: Statistics generated from findings
            
        Returns:
            Security score between 0 and 100
        """
        if not findings:
            return 100.0  # Perfect score for no findings
        
        # Calculate base score from severity counts
        severity_weights = {
            "critical": 10.0,
            "high": 5.0,
            "medium": 2.0,
            "low": 0.5
        }
        
        severity_counts = statistics["severity_counts"]
        severity_score = sum(count * severity_weights[level] for level, count in severity_counts.items())
        
        # Normalize to 0-100 scale, with lower scores for more severe findings
        # We'll use an exponential scale to emphasize critical findings
        normalized_score = 100 * np.exp(-severity_score / 20.0)
        
        # Ensure the score is between 0 and 100
        return max(0.0, min(100.0, normalized_score))
    
    def _calculate_miner_contributions(self,
                                      findings: List[VulnerabilityFinding],
                                      miner_responses: Dict[str, Any],
                                      miner_weights: Dict[str, float]) -> Dict[str, Dict[str, Any]]:
        """
        Calculate contribution metrics for each miner.
        
        Args:
            findings: List of consolidated findings
            miner_responses: Original miner responses
            miner_weights: Dictionary mapping miner IDs to their weights
            
        Returns:
            Dictionary mapping miner IDs to their contribution metrics
        """
        contributions = {}
        
        for miner_id in miner_responses:
            # Count findings where this miner contributed
            contributed_findings = [f for f in findings if miner_id in f.miners]
            
            # Count true positives (findings with high confidence)
            true_positives = [f for f in contributed_findings if f.confidence >= 0.6]
            
            # Count potential false positives (findings with low confidence)
            potential_false_positives = [f for f in contributed_findings if f.confidence < 0.3]
            
            # Count findings by severity
            severity_counts = {
                "critical": sum(1 for f in contributed_findings if f.severity >= 9.0),
                "high": sum(1 for f in contributed_findings if 7.0 <= f.severity < 9.0),
                "medium": sum(1 for f in contributed_findings if 4.0 <= f.severity < 7.0),
                "low": sum(1 for f in contributed_findings if f.severity < 4.0)
            }
            
            # Calculate unique contribution (findings where this miner is the only one)
            unique_findings = [f for f in findings if f.miners == [miner_id]]
            
            # Calculate agreement with consensus (percentage of findings where miner agrees with consensus)
            if findings:
                agreement_with_consensus = len(contributed_findings) / len(findings)
            else:
                agreement_with_consensus = 0.0
            
            contributions[miner_id] = {
                "total_contributions": len(contributed_findings),
                "true_positives": len(true_positives),
                "potential_false_positives": len(potential_false_positives),
                "severity_counts": severity_counts,
                "unique_findings": len(unique_findings),
                "agreement_with_consensus": agreement_with_consensus,
                "weighted_score": miner_weights.get(miner_id, 0.0)
            }
        
        return contributions
    
    def _save_report(self, report: VulnerabilityReport) -> None:
        """
        Save a report to disk.
        
        Args:
            report: VulnerabilityReport to save
        """
        try:
            filename = f"{report.project_name.replace(' ', '_')}_{report.report_id}.json"
            output_path = self.storage_path / filename
            report.save_json(str(output_path))
            self.logger.info(f"Saved report to {output_path}")
        except Exception as e:
            self.logger.error(f"Error saving report: {e}")
    
    def generate_html_report(self, report: VulnerabilityReport) -> str:
        """
        Generate an HTML version of the report.
        
        Args:
            report: VulnerabilityReport to convert to HTML
            
        Returns:
            HTML string representation of the report
        """
        try:
            # Generate graphs and charts
            severity_chart = self._generate_severity_chart(report)
            type_chart = self._generate_type_chart(report)
            
            # Convert findings to HTML
            findings_html = self._findings_to_html(report.findings)
            
            # Generate miner contributions HTML
            contributions_html = self._contributions_to_html(report.miner_contributions)
            
            # Generate HTML template
            html = f"""
            <!DOCTYPE html>
            <html>
            <head>
                <title>Security Vulnerability Report - {report.project_name}</title>
                <style>
                    body {{ font-family: Arial, sans-serif; line-height: 1.6; color: #333; max-width: 1200px; margin: 0 auto; padding: 20px; }}
                    h1, h2, h3 {{ color: #2c3e50; }}
                    .header {{ display: flex; justify-content: space-between; align-items: center; margin-bottom: 20px; }}
                    .score-box {{ padding: 20px; border-radius: 8px; width: 200px; text-align: center; }}
                    .high-score {{ background-color: #dff0d8; color: #3c763d; }}
                    .medium-score {{ background-color: #fcf8e3; color: #8a6d3b; }}
                    .low-score {{ background-color: #f2dede; color: #a94442; }}
                    .chart-container {{ display: flex; justify-content: space-between; margin: 20px 0; }}
                    .chart {{ width: 48%; }}
                    .finding {{ border: 1px solid #ddd; border-radius: 5px; padding: 15px; margin-bottom: 15px; }}
                    .critical {{ border-left: 5px solid #d9534f; }}
                    .high {{ border-left: 5px solid #f0ad4e; }}
                    .medium {{ border-left: 5px solid #5bc0de; }}
                    .low {{ border-left: 5px solid #5cb85c; }}
                    .stats-table {{ width: 100%; border-collapse: collapse; margin: 20px 0; }}
                    .stats-table th, .stats-table td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}
                    .stats-table th {{ background-color: #f8f9fa; }}
                    .code-snippet {{ background-color: #f8f9fa; padding: 10px; border-radius: 5px; overflow-x: auto; font-family: monospace; }}
                    .section {{ margin-bottom: 30px; }}
                </style>
            </head>
            <body>
                <div class="header">
                    <div>
                        <h1>Security Vulnerability Report</h1>
                        <p><strong>Project:</strong> {report.project_name}</p>
                        <p><strong>Report ID:</strong> {report.report_id}</p>
                        <p><strong>Generated:</strong> {report.timestamp.strftime('%Y-%m-%d %H:%M:%S')}</p>
                    </div>
                    <div class="score-box {self._get_score_class(report.overall_security_score)}">
                        <h2>Security Score</h2>
                        <h1>{report.overall_security_score:.1f}%</h1>
                    </div>
                </div>
                
                <div class="section">
                    <h2>Summary</h2>
                    <p><strong>Total Findings:</strong> {report.statistics["consensus_stats"]["total_findings"]}</p>
                    <p><strong>Critical Severity:</strong> {report.statistics["severity_counts"]["critical"]}</p>
                    <p><strong>High Severity:</strong> {report.statistics["severity_counts"]["high"]}</p>
                    <p><strong>Medium Severity:</strong> {report.statistics["severity_counts"]["medium"]}</p>
                    <p><strong>Low Severity:</strong> {report.statistics["severity_counts"]["low"]}</p>
                </div>
                
                <div class="chart-container">
                    <div class="chart">
                        <h3>Findings by Severity</h3>
                        <img src="data:image/png;base64,{severity_chart}" alt="Severity Distribution" style="max-width: 100%;">
                    </div>
                    <div class="chart">
                        <h3>Top Vulnerability Types</h3>
                        <img src="data:image/png;base64,{type_chart}" alt="Vulnerability Types" style="max-width: 100%;">
                    </div>
                </div>
                
                <div class="section">
                    <h2>Most Vulnerable Files</h2>
                    <table class="stats-table">
                        <tr>
                            <th>File</th>
                            <th>Findings</th>
                        </tr>
                        {"".join([f"<tr><td>{file}</td><td>{count}</td></tr>" for file, count in report.statistics["top_vulnerable_files"].items()])}
                    </table>
                </div>
                
                <div class="section">
                    <h2>Detailed Findings</h2>
                    {findings_html}
                </div>
                
                <div class="section">
                    <h2>Miner Contributions</h2>
                    {contributions_html}
                </div>
            </body>
            </html>
            """
            
            return html
            
        except Exception as e:
            self.logger.error(f"Error generating HTML report: {e}")
            return f"<html><body><h1>Error generating report</h1><p>{str(e)}</p></body></html>"
    
    def _get_score_class(self, score: float) -> str:
        """Get CSS class based on security score."""
        if score >= 80:
            return "high-score"
        elif score >= 50:
            return "medium-score"
        else:
            return "low-score"
    
    def _generate_severity_chart(self, report: VulnerabilityReport) -> str:
        """Generate base64-encoded severity chart image."""
        try:
            # Clear any existing plots
            plt.figure(figsize=(6, 4))
            
            # Prepare data
            severity_counts = report.statistics["severity_counts"]
            labels = list(severity_counts.keys())
            sizes = list(severity_counts.values())
            colors = ['#d9534f', '#f0ad4e', '#5bc0de', '#5cb85c']
            
            # Create pie chart
            patches, texts, autotexts = plt.pie(
                sizes, 
                labels=labels, 
                colors=colors,
                autopct='%1.1f%%', 
                startangle=90,
                textprops={'fontsize': 10}
            )
            plt.axis('equal')
            
            # Save to bytes buffer
            buffer = BytesIO()
            plt.savefig(buffer, format='png', bbox_inches='tight')
            plt.close()
            
            # Convert to base64
            buffer.seek(0)
            image_base64 = base64.b64encode(buffer.getvalue()).decode('utf-8')
            
            return image_base64
            
        except Exception as e:
            self.logger.error(f"Error generating severity chart: {e}")
            return ""
    
    def _generate_type_chart(self, report: VulnerabilityReport) -> str:
        """Generate base64-encoded vulnerability types chart image."""
        try:
            # Clear any existing plots
            plt.figure(figsize=(6, 4))
            
            # Prepare data
            type_counts = report.statistics["type_counts"]
            
            # Get top 5 types
            top_types = sorted(type_counts.items(), key=lambda x: x[1], reverse=True)[:5]
            types = [t[0] for t in top_types]
            counts = [t[1] for t in top_types]
            
            # Create horizontal bar chart
            y_pos = np.arange(len(types))
            plt.barh(y_pos, counts, color='skyblue')
            plt.yticks(y_pos, types)
            plt.xlabel('Number of Findings')
            plt.title('Top Vulnerability Types')
            
            # Save to bytes buffer
            buffer = BytesIO()
            plt.savefig(buffer, format='png', bbox_inches='tight')
            plt.close()
            
            # Convert to base64
            buffer.seek(0)
            image_base64 = base64.b64encode(buffer.getvalue()).decode('utf-8')
            
            return image_base64
            
        except Exception as e:
            self.logger.error(f"Error generating type chart: {e}")
            return ""
    
    def _findings_to_html(self, findings: List[VulnerabilityFinding]) -> str:
        """Convert findings to HTML representation."""
        html = ""
        
        for i, finding in enumerate(findings):
            # Determine severity class
            severity_class = "low"
            if finding.severity >= 9.0:
                severity_class = "critical"
            elif finding.severity >= 7.0:
                severity_class = "high"
            elif finding.severity >= 4.0:
                severity_class = "medium"
            
            # Format location
            location = f"{finding.location.file_path}:{finding.location.line_start}"
            if finding.location.line_end and finding.location.line_end != finding.location.line_start:
                location += f"-{finding.location.line_end}"
            
            # Format findings
            html += f"""
            <div class="finding {severity_class}">
                <h3>{i+1}. {finding.vulnerability_type}</h3>
                <p><strong>Location:</strong> {location}</p>
                <p><strong>Severity:</strong> {finding.severity:.1f}/10 (Confidence: {finding.confidence:.1f})</p>
                <p><strong>Description:</strong> {finding.description}</p>
                <p><strong>Recommendation:</strong> {finding.recommendation}</p>
                <p><strong>Reported by:</strong> {len(finding.miners)} miners</p>
            """
            
            # Add code snippet if available
            if finding.code_snippet:
                html += f"""
                <h4>Code:</h4>
                <pre class="code-snippet">{finding.code_snippet}</pre>
                """
            
            # Add exploit scenario if available
            if finding.exploit_scenario:
                html += f"""
                <h4>Exploit Scenario:</h4>
                <p>{finding.exploit_scenario}</p>
                """
            
            # Add references if available
            if finding.references:
                html += f"""
                <h4>References:</h4>
                <ul>{"".join([f"<li>{ref}</li>" for ref in finding.references])}</ul>
                """
            
            html += "</div>"
        
        return html
    
    def _contributions_to_html(self, contributions: Dict[str, Dict[str, Any]]) -> str:
        """Convert miner contributions to HTML representation."""
        # Convert to pandas DataFrame for easier manipulation
        data = []
        for miner_id, metrics in contributions.items():
            row = {
                "Miner ID": miner_id[:10] + "...",
                "Total Findings": metrics["total_contributions"],
                "True Positives": metrics["true_positives"],
                "Potential False Positives": metrics["potential_false_positives"],
                "Critical": metrics["severity_counts"]["critical"],
                "High": metrics["severity_counts"]["high"],
                "Medium": metrics["severity_counts"]["medium"],
                "Low": metrics["severity_counts"]["low"],
                "Unique Findings": metrics["unique_findings"],
                "Agreement with Consensus": f"{metrics['agreement_with_consensus']*100:.1f}%",
                "Weight": f"{metrics['weighted_score']:.3f}"
            }
            data.append(row)
        
        df = pd.DataFrame(data)
        
        # Convert DataFrame to HTML table
        table_html = df.to_html(classes="stats-table", index=False)
        
        return f"""
        <div>
            {table_html}
        </div>
        """
    
    def save_html_report(self, report: VulnerabilityReport, output_path: Optional[str] = None) -> str:
        """
        Generate and save an HTML report.
        
        Args:
            report: VulnerabilityReport to convert to HTML
            output_path: Path to save the HTML report (optional)
            
        Returns:
            Path to the saved HTML report
        """
        html = self.generate_html_report(report)
        
        if output_path is None:
            filename = f"{report.project_name.replace(' ', '_')}_{report.report_id}.html"
            output_path = str(self.storage_path / filename)
        
        try:
            with open(output_path, 'w') as f:
                f.write(html)
            
            self.logger.info(f"Saved HTML report to {output_path}")
            return output_path
            
        except Exception as e:
            self.logger.error(f"Error saving HTML report: {e}")
            return "" 